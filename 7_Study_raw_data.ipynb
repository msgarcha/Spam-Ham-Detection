{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Studying the effects of changing the data and running the same models and creating new models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "os.chdir(\"..\")\n",
    "\n",
    "from sklearn.cross_validation import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "enron7 = pd.read_csv(\"Res/Complete_data_processed/enron7.csv\",sep=\",\")\n",
    "enron8 = pd.read_csv(\"Res/Complete_data_processed/enron8.csv\",sep=\",\")\n",
    "enron9 = pd.read_csv(\"Res/Complete_data_processed/enron9.csv\",sep=\",\")\n",
    "enron10 = pd.read_csv(\"Res/Complete_data_processed/enron10.csv\",sep=\",\")\n",
    "enron11 = pd.read_csv(\"Res/Complete_data_processed/enron11.csv\",sep=\",\")\n",
    "enron12 = pd.read_csv(\"Res/Complete_data_processed/enron12.csv\",sep=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 1229\n",
      "True Negatives(ham)  = 3316\n",
      "False Positives(actual=ham, predicted=spam) = 346\n",
      "False Negatives(actual=spam,predicted=ham) = 101\n",
      "Accuracy = 91.05%\n",
      "Recall = 92.41%\n",
      "Specificity = 90.55%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 1068\n",
      "True Negatives(ham)  = 2994\n",
      "False Positives(actual=ham, predicted=spam) = 668\n",
      "False Negatives(actual=spam,predicted=ham) = 262\n",
      "Accuracy = 81.37%\n",
      "Recall = 80.30%\n",
      "Specificity = 81.76%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n",
      "True Positives(spam) = 877\n",
      "True Negatives(ham)  = 2604\n",
      "False Positives(actual=ham, predicted=spam) = 1058\n",
      "False Negatives(actual=spam,predicted=ham) = 453\n",
      "Accuracy = 69.73%\n",
      "Recall = 65.94%\n",
      "Specificity = 71.11%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 1324\n",
      "True Negatives(ham)  = 1575\n",
      "False Positives(actual=ham, predicted=spam) = 2087\n",
      "False Negatives(actual=spam,predicted=ham) = 6\n",
      "Accuracy = 58.07%\n",
      "Recall = 99.55%\n",
      "Specificity = 43.01%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 1226\n",
      "True Negatives(ham)  = 2436\n",
      "False Positives(actual=ham, predicted=spam) = 1226\n",
      "False Negatives(actual=spam,predicted=ham) = 104\n",
      "Accuracy = 73.36%\n",
      "Recall = 92.18%\n",
      "Specificity = 66.52%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 1140\n",
      "True Negatives(ham)  = 2583\n",
      "False Positives(actual=ham, predicted=spam) = 1079\n",
      "False Negatives(actual=spam,predicted=ham) = 190\n",
      "Accuracy = 74.58%\n",
      "Recall = 85.71%\n",
      "Specificity = 70.54%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 1250\n",
      "True Negatives(ham)  = 3198\n",
      "False Positives(actual=ham, predicted=spam) = 1158\n",
      "False Negatives(actual=spam,predicted=ham) = 40\n",
      "Accuracy = 78.78%\n",
      "Recall = 96.90%\n",
      "Specificity = 73.42%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 1161\n",
      "True Negatives(ham)  = 4193\n",
      "False Positives(actual=ham, predicted=spam) = 163\n",
      "False Negatives(actual=spam,predicted=ham) = 129\n",
      "Accuracy = 94.83%\n",
      "Recall = 90.00%\n",
      "Specificity = 96.26%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n",
      "True Positives(spam) = 1238\n",
      "True Negatives(ham)  = 3372\n",
      "False Positives(actual=ham, predicted=spam) = 984\n",
      "False Negatives(actual=spam,predicted=ham) = 52\n",
      "Accuracy = 81.65%\n",
      "Recall = 95.97%\n",
      "Specificity = 77.41%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 1288\n",
      "True Negatives(ham)  = 2260\n",
      "False Positives(actual=ham, predicted=spam) = 2096\n",
      "False Negatives(actual=spam,predicted=ham) = 2\n",
      "Accuracy = 62.84%\n",
      "Recall = 99.84%\n",
      "Specificity = 51.88%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 1275\n",
      "True Negatives(ham)  = 3024\n",
      "False Positives(actual=ham, predicted=spam) = 1332\n",
      "False Negatives(actual=spam,predicted=ham) = 15\n",
      "Accuracy = 76.14%\n",
      "Recall = 98.84%\n",
      "Specificity = 69.42%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 1251\n",
      "True Negatives(ham)  = 2868\n",
      "False Positives(actual=ham, predicted=spam) = 1488\n",
      "False Negatives(actual=spam,predicted=ham) = 39\n",
      "Accuracy = 72.95%\n",
      "Recall = 96.98%\n",
      "Specificity = 65.84%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 1302\n",
      "True Negatives(ham)  = 1735\n",
      "False Positives(actual=ham, predicted=spam) = 612\n",
      "False Negatives(actual=spam,predicted=ham) = 85\n",
      "Accuracy = 81.33%\n",
      "Recall = 93.87%\n",
      "Specificity = 73.92%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 1237\n",
      "True Negatives(ham)  = 1847\n",
      "False Positives(actual=ham, predicted=spam) = 500\n",
      "False Negatives(actual=spam,predicted=ham) = 150\n",
      "Accuracy = 82.59%\n",
      "Recall = 89.19%\n",
      "Specificity = 78.70%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n",
      "True Positives(spam) = 1143\n",
      "True Negatives(ham)  = 1894\n",
      "False Positives(actual=ham, predicted=spam) = 453\n",
      "False Negatives(actual=spam,predicted=ham) = 244\n",
      "Accuracy = 81.33%\n",
      "Recall = 82.41%\n",
      "Specificity = 80.70%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 1383\n",
      "True Negatives(ham)  = 1127\n",
      "False Positives(actual=ham, predicted=spam) = 1220\n",
      "False Negatives(actual=spam,predicted=ham) = 4\n",
      "Accuracy = 67.22%\n",
      "Recall = 99.71%\n",
      "Specificity = 48.02%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 1348\n",
      "True Negatives(ham)  = 1392\n",
      "False Positives(actual=ham, predicted=spam) = 955\n",
      "False Negatives(actual=spam,predicted=ham) = 39\n",
      "Accuracy = 73.38%\n",
      "Recall = 97.19%\n",
      "Specificity = 59.31%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 1292\n",
      "True Negatives(ham)  = 1946\n",
      "False Positives(actual=ham, predicted=spam) = 401\n",
      "False Negatives(actual=spam,predicted=ham) = 95\n",
      "Accuracy = 86.72%\n",
      "Recall = 93.15%\n",
      "Specificity = 82.91%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 1355\n",
      "True Negatives(ham)  = 605\n",
      "False Positives(actual=ham, predicted=spam) = 893\n",
      "False Negatives(actual=spam,predicted=ham) = 111\n",
      "Accuracy = 66.13%\n",
      "Recall = 92.43%\n",
      "Specificity = 40.39%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 1185\n",
      "True Negatives(ham)  = 553\n",
      "False Positives(actual=ham, predicted=spam) = 945\n",
      "False Negatives(actual=spam,predicted=ham) = 281\n",
      "Accuracy = 58.64%\n",
      "Recall = 80.83%\n",
      "Specificity = 36.92%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n",
      "True Positives(spam) = 969\n",
      "True Negatives(ham)  = 640\n",
      "False Positives(actual=ham, predicted=spam) = 858\n",
      "False Negatives(actual=spam,predicted=ham) = 497\n",
      "Accuracy = 54.28%\n",
      "Recall = 66.10%\n",
      "Specificity = 42.72%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 1460\n",
      "True Negatives(ham)  = 1333\n",
      "False Positives(actual=ham, predicted=spam) = 165\n",
      "False Negatives(actual=spam,predicted=ham) = 6\n",
      "Accuracy = 94.23%\n",
      "Recall = 99.59%\n",
      "Specificity = 88.99%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 1348\n",
      "True Negatives(ham)  = 407\n",
      "False Positives(actual=ham, predicted=spam) = 1091\n",
      "False Negatives(actual=spam,predicted=ham) = 118\n",
      "Accuracy = 59.21%\n",
      "Recall = 91.95%\n",
      "Specificity = 27.17%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 1255\n",
      "True Negatives(ham)  = 412\n",
      "False Positives(actual=ham, predicted=spam) = 1086\n",
      "False Negatives(actual=spam,predicted=ham) = 211\n",
      "Accuracy = 56.24%\n",
      "Recall = 85.61%\n",
      "Specificity = 27.50%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 3767\n",
      "True Negatives(ham)  = 1178\n",
      "False Positives(actual=ham, predicted=spam) = 321\n",
      "False Negatives(actual=spam,predicted=ham) = 111\n",
      "Accuracy = 91.97%\n",
      "Recall = 97.14%\n",
      "Specificity = 78.59%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 3418\n",
      "True Negatives(ham)  = 1315\n",
      "False Positives(actual=ham, predicted=spam) = 184\n",
      "False Negatives(actual=spam,predicted=ham) = 460\n",
      "Accuracy = 88.02%\n",
      "Recall = 88.14%\n",
      "Specificity = 87.73%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n",
      "True Positives(spam) = 3676\n",
      "True Negatives(ham)  = 1269\n",
      "False Positives(actual=ham, predicted=spam) = 230\n",
      "False Negatives(actual=spam,predicted=ham) = 202\n",
      "Accuracy = 91.97%\n",
      "Recall = 94.79%\n",
      "Specificity = 84.66%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 3870\n",
      "True Negatives(ham)  = 767\n",
      "False Positives(actual=ham, predicted=spam) = 732\n",
      "False Negatives(actual=spam,predicted=ham) = 8\n",
      "Accuracy = 86.24%\n",
      "Recall = 99.79%\n",
      "Specificity = 51.17%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 3824\n",
      "True Negatives(ham)  = 1351\n",
      "False Positives(actual=ham, predicted=spam) = 148\n",
      "False Negatives(actual=spam,predicted=ham) = 54\n",
      "Accuracy = 96.24%\n",
      "Recall = 98.61%\n",
      "Specificity = 90.13%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 3748\n",
      "True Negatives(ham)  = 1074\n",
      "False Positives(actual=ham, predicted=spam) = 425\n",
      "False Negatives(actual=spam,predicted=ham) = 130\n",
      "Accuracy = 89.68%\n",
      "Recall = 96.65%\n",
      "Specificity = 71.65%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 1\n",
      "True Positives(spam) = 3927\n",
      "True Negatives(ham)  = 1103\n",
      "False Positives(actual=ham, predicted=spam) = 390\n",
      "False Negatives(actual=spam,predicted=ham) = 265\n",
      "Accuracy = 88.48%\n",
      "Recall = 93.68%\n",
      "Specificity = 73.88%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 2\n",
      "True Positives(spam) = 3700\n",
      "True Negatives(ham)  = 1141\n",
      "False Positives(actual=ham, predicted=spam) = 352\n",
      "False Negatives(actual=spam,predicted=ham) = 492\n",
      "Accuracy = 85.15%\n",
      "Recall = 88.26%\n",
      "Specificity = 76.42%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives(spam) = 3497\n",
      "True Negatives(ham)  = 1409\n",
      "False Positives(actual=ham, predicted=spam) = 84\n",
      "False Negatives(actual=spam,predicted=ham) = 695\n",
      "Accuracy = 86.30%\n",
      "Recall = 83.42%\n",
      "Specificity = 94.37%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 4\n",
      "True Positives(spam) = 4175\n",
      "True Negatives(ham)  = 790\n",
      "False Positives(actual=ham, predicted=spam) = 703\n",
      "False Negatives(actual=spam,predicted=ham) = 17\n",
      "Accuracy = 87.34%\n",
      "Recall = 99.59%\n",
      "Specificity = 52.91%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 5\n",
      "True Positives(spam) = 4063\n",
      "True Negatives(ham)  = 936\n",
      "False Positives(actual=ham, predicted=spam) = 557\n",
      "False Negatives(actual=spam,predicted=ham) = 129\n",
      "Accuracy = 87.93%\n",
      "Recall = 96.92%\n",
      "Specificity = 62.69%\n",
      "\n",
      "\n",
      "Running the model trained from Enron data : 6\n",
      "True Positives(spam) = 3940\n",
      "True Negatives(ham)  = 1036\n",
      "False Positives(actual=ham, predicted=spam) = 457\n",
      "False Negatives(actual=spam,predicted=ham) = 252\n",
      "Accuracy = 87.53%\n",
      "Recall = 93.99%\n",
      "Specificity = 69.39%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Studying the accuracy using the xgboost models built from enron 1 to enron 6 dataset\n",
    "new_enron_accuracy_df = pd.DataFrame(columns=[\"Enron_dataset\",\"model_name\",\"spam\",\"ham\",\"tp\",\"tn\",\"fp\",\"fn\"\n",
    "                                              ,\"acc\",\"recall\",\"specificity\"])\n",
    "enron_dataset_list_df = [enron7,enron8,enron9,enron10,enron11,enron12]\n",
    "new_enron_list = [\"Enron\"+str(i) for i in range(7,13)]\n",
    "i=0\n",
    "j=-1\n",
    "for enron_dataset in enron_dataset_list_df:\n",
    "    j+=1\n",
    "    print(\"Working on the \"+new_enron_list[j])\n",
    "    model_no_list = range(1,7)\n",
    "    # Adding some of the attributes that are missing in the data that we created now to test against the models 1 to 6\n",
    "    for col in ['additiona','aiso','andmanyother','beiieves','couid','dbcaps','enronxgate','hplno',\n",
    "                        'inciude','inciuding','invoive','lst','maiiings','majordomo','newsietter',\n",
    "                        'piaced','pians','potentia','projecthoneypot','pubiisher','resuits','shouid',\n",
    "                        'squirrelmail','technoiogies','technoiogy','utf']:\n",
    "        enron_dataset[col]=0.0\n",
    "    for model_no in model_no_list:\n",
    "        print(\"Running the model trained from Enron data : \"+str(model_no))\n",
    "        col_attributes = []\n",
    "        with open(\"Res/processed_data/attributes_names.txt\", 'r') as f:\n",
    "            col_attributes.extend(f.read().split())\n",
    "        baseline_X_features = ['line_count', 'token_count', 'punctuations_count', 'single_char_count', \n",
    "                                 'number_token_count', 'year_count', 'stopword_count','median_useful_token_len', \n",
    "                                 'avg_useful_token_len', 'rareword_count','attributes_len']\n",
    "        baseline_X_features.extend(col_attributes)\n",
    "\n",
    "        import pickle\n",
    "        import xgboost as xgb\n",
    "        # load model from file\n",
    "        loaded_xgb = pickle.load(open(\"Res/\"+\"enron\"+str(model_no)+\"_xgboost.pickle.dat\", \"rb\"))\n",
    "        \n",
    "        spam=enron_dataset.loc[enron_dataset[\"mail_label\"]==\"spam\"]\n",
    "        ham=enron_dataset.loc[enron_dataset[\"mail_label\"]==\"ham\"]\n",
    "        \n",
    "        enron_dataset[\"label\"] = pd.Series(enron_dataset[\"mail_label\"]).apply(lambda x: 1.0 if x==\"spam\" else 0.0)\n",
    "        dtest = xgb.DMatrix(enron_dataset[baseline_X_features], label=enron_dataset[\"label\"])\n",
    "        y_pred = loaded_xgb.predict(dtest)\n",
    "        y_probas = y_pred # predicted probabilities generated by sklearn classifier\n",
    "        y_pred = pd.Series(y_pred).apply(lambda x: 1.0 if x>0.5 else 0.0)\n",
    "\n",
    "        dfs = pd.DataFrame(columns = [\"Actual\",\"Pred\"])\n",
    "        dfs[\"Actual\"]=enron_dataset[\"label\"]\n",
    "        dfs[\"Pred_probs\"]=loaded_xgb.predict(dtest)\n",
    "        dfs[\"Pred\"] = dfs.apply(lambda row:1.0 if row[\"Pred_probs\"]>0.5 else 0.0,axis=1)\n",
    "\n",
    "        from sklearn.metrics import confusion_matrix\n",
    "\n",
    "        y_test = dfs[\"Actual\"]\n",
    "        y_pred = dfs[\"Pred\"]\n",
    "\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        print(\"True Positives(spam) = {}\".format(tp))\n",
    "        print(\"True Negatives(ham)  = {}\".format(tn))\n",
    "        print(\"False Positives(actual=ham, predicted=spam) = {}\".format(fp))\n",
    "        print(\"False Negatives(actual=spam,predicted=ham) = {}\".format(fn))\n",
    "        print(\"Accuracy = {:.2f}%\".format((tp+tn)/float(len(y_test))*100))\n",
    "        print(\"Recall = {:.2f}%\".format((tp/float(tp+fn))*100))\n",
    "        print(\"Specificity = {:.2f}%\".format((tn/float(tn+fp))*100))\n",
    "        \n",
    "        new_enron_accuracy_df.loc[i]=[new_enron_list[j],\"enron\"+str(model_no)+\"_xgboost\",\n",
    "                                      len(spam),len(ham),tp, tn, fp, fn,\n",
    "                                      (tp+tn)/float(len(spam)+len(ham))*100,\n",
    "                                      (tp/float(tp+fn))*100,\n",
    "                                      (tn/float(tn+fp))*100]\n",
    "        i+=1\n",
    "        print(\"\\n\")\n",
    "new_enron_accuracy_df.to_csv(\"Res/Complete_data_processed/new_enron_accuracy.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\teval-auc:0.944925\ttrain-auc:0.994251\n",
      "[1]\teval-auc:0.974228\ttrain-auc:0.998811\n",
      "[2]\teval-auc:0.981259\ttrain-auc:0.999487\n",
      "[3]\teval-auc:0.988971\ttrain-auc:0.99988\n",
      "[4]\teval-auc:0.991066\ttrain-auc:0.999934\n",
      "[5]\teval-auc:0.991904\ttrain-auc:0.999972\n",
      "[6]\teval-auc:0.992486\ttrain-auc:0.999986\n",
      "[7]\teval-auc:0.992707\ttrain-auc:0.99999\n",
      "[8]\teval-auc:0.992681\ttrain-auc:0.999993\n",
      "[9]\teval-auc:0.992727\ttrain-auc:0.999993\n",
      "[10]\teval-auc:0.992758\ttrain-auc:0.999993\n",
      "[11]\teval-auc:0.993281\ttrain-auc:0.999995\n",
      "[12]\teval-auc:0.993112\ttrain-auc:0.999996\n",
      "[13]\teval-auc:0.993235\ttrain-auc:0.999997\n",
      "[14]\teval-auc:0.993348\ttrain-auc:0.999997\n",
      "[15]\teval-auc:0.993399\ttrain-auc:0.999997\n",
      "[16]\teval-auc:0.993527\ttrain-auc:0.999996\n",
      "[17]\teval-auc:0.993527\ttrain-auc:0.999997\n",
      "[18]\teval-auc:0.993461\ttrain-auc:0.999997\n",
      "[19]\teval-auc:0.993343\ttrain-auc:0.999996\n",
      "[20]\teval-auc:0.993158\ttrain-auc:0.999997\n",
      "[21]\teval-auc:0.993056\ttrain-auc:0.999997\n",
      "[22]\teval-auc:0.992733\ttrain-auc:0.999997\n",
      "[23]\teval-auc:0.992861\ttrain-auc:0.999997\n",
      "[24]\teval-auc:0.992938\ttrain-auc:0.999997\n",
      "[25]\teval-auc:0.993035\ttrain-auc:0.999997\n",
      "[26]\teval-auc:0.992943\ttrain-auc:0.999997\n",
      "[27]\teval-auc:0.992871\ttrain-auc:0.999997\n",
      "[28]\teval-auc:0.992804\ttrain-auc:0.999997\n",
      "[29]\teval-auc:0.992784\ttrain-auc:0.999997\n",
      "True Positives(spam) = 250\n",
      "True Negatives(ham)  = 712\n",
      "False Positives(actual=ham, predicted=spam) = 21\n",
      "False Negatives(actual=spam,predicted=ham) = 16\n",
      "Accuracy = 96.20%\n",
      "Recall = 93.98%\n",
      "Specificity = 97.14%\n",
      "[0]\teval-auc:0.986316\ttrain-auc:0.997276\n",
      "[1]\teval-auc:0.994346\ttrain-auc:0.99972\n",
      "[2]\teval-auc:0.995193\ttrain-auc:0.999978\n",
      "[3]\teval-auc:0.99544\ttrain-auc:0.999997\n",
      "[4]\teval-auc:0.996026\ttrain-auc:1\n",
      "[5]\teval-auc:0.996737\ttrain-auc:1\n",
      "[6]\teval-auc:0.996306\ttrain-auc:1\n",
      "[7]\teval-auc:0.996542\ttrain-auc:1\n",
      "[8]\teval-auc:0.99656\ttrain-auc:1\n",
      "[9]\teval-auc:0.996813\ttrain-auc:1\n",
      "[10]\teval-auc:0.997049\ttrain-auc:1\n",
      "[11]\teval-auc:0.997009\ttrain-auc:1\n",
      "[12]\teval-auc:0.996884\ttrain-auc:1\n",
      "[13]\teval-auc:0.99684\ttrain-auc:1\n",
      "[14]\teval-auc:0.996911\ttrain-auc:1\n",
      "[15]\teval-auc:0.996715\ttrain-auc:1\n",
      "[16]\teval-auc:0.996613\ttrain-auc:1\n",
      "[17]\teval-auc:0.996782\ttrain-auc:1\n",
      "[18]\teval-auc:0.996769\ttrain-auc:1\n",
      "[19]\teval-auc:0.996786\ttrain-auc:1\n",
      "[20]\teval-auc:0.996711\ttrain-auc:1\n",
      "[21]\teval-auc:0.996849\ttrain-auc:1\n",
      "[22]\teval-auc:0.996893\ttrain-auc:1\n",
      "[23]\teval-auc:0.996969\ttrain-auc:1\n",
      "[24]\teval-auc:0.99688\ttrain-auc:1\n",
      "[25]\teval-auc:0.996724\ttrain-auc:1\n",
      "[26]\teval-auc:0.996755\ttrain-auc:1\n",
      "[27]\teval-auc:0.9968\ttrain-auc:1\n",
      "[28]\teval-auc:0.996546\ttrain-auc:1\n",
      "[29]\teval-auc:0.996524\ttrain-auc:1\n",
      "True Positives(spam) = 250\n",
      "True Negatives(ham)  = 866\n",
      "False Positives(actual=ham, predicted=spam) = 6\n",
      "False Negatives(actual=spam,predicted=ham) = 8\n",
      "Accuracy = 98.67%\n",
      "Recall = 96.90%\n",
      "Specificity = 99.31%\n",
      "[0]\teval-auc:0.971112\ttrain-auc:0.996808\n",
      "[1]\teval-auc:0.967913\ttrain-auc:0.999604\n",
      "[2]\teval-auc:0.982998\ttrain-auc:0.999939\n",
      "[3]\teval-auc:0.984992\ttrain-auc:0.999994\n",
      "[4]\teval-auc:0.986163\ttrain-auc:0.999999\n",
      "[5]\teval-auc:0.989591\ttrain-auc:0.999997\n",
      "[6]\teval-auc:0.990005\ttrain-auc:0.999999\n",
      "[7]\teval-auc:0.989982\ttrain-auc:0.999999\n",
      "[8]\teval-auc:0.9894\ttrain-auc:1\n",
      "[9]\teval-auc:0.989232\ttrain-auc:1\n",
      "[10]\teval-auc:0.98914\ttrain-auc:1\n",
      "[11]\teval-auc:0.989568\ttrain-auc:1\n",
      "[12]\teval-auc:0.989591\ttrain-auc:1\n",
      "[13]\teval-auc:0.989025\ttrain-auc:1\n",
      "[14]\teval-auc:0.988872\ttrain-auc:1\n",
      "[15]\teval-auc:0.989178\ttrain-auc:1\n",
      "[16]\teval-auc:0.98891\ttrain-auc:1\n",
      "[17]\teval-auc:0.988918\ttrain-auc:1\n",
      "[18]\teval-auc:0.988772\ttrain-auc:1\n",
      "[19]\teval-auc:0.989255\ttrain-auc:1\n",
      "[20]\teval-auc:0.989285\ttrain-auc:1\n",
      "[21]\teval-auc:0.988941\ttrain-auc:1\n",
      "[22]\teval-auc:0.989025\ttrain-auc:1\n",
      "[23]\teval-auc:0.989163\ttrain-auc:1\n",
      "[24]\teval-auc:0.989339\ttrain-auc:1\n",
      "[25]\teval-auc:0.988734\ttrain-auc:1\n",
      "[26]\teval-auc:0.988367\ttrain-auc:1\n",
      "[27]\teval-auc:0.98901\ttrain-auc:1\n",
      "[28]\teval-auc:0.98914\ttrain-auc:1\n",
      "[29]\teval-auc:0.989155\ttrain-auc:1\n",
      "True Positives(spam) = 259\n",
      "True Negatives(ham)  = 456\n",
      "False Positives(actual=ham, predicted=spam) = 14\n",
      "False Negatives(actual=spam,predicted=ham) = 19\n",
      "Accuracy = 95.46%\n",
      "Recall = 93.17%\n",
      "Specificity = 97.02%\n",
      "[0]\teval-auc:0.963464\ttrain-auc:0.997497\n",
      "[1]\teval-auc:0.971066\ttrain-auc:0.998633\n",
      "[2]\teval-auc:0.973464\ttrain-auc:0.999365\n",
      "[3]\teval-auc:0.976292\ttrain-auc:0.999755\n",
      "[4]\teval-auc:0.979246\ttrain-auc:0.999862\n",
      "[5]\teval-auc:0.979728\ttrain-auc:0.999837\n",
      "[6]\teval-auc:0.981304\ttrain-auc:0.999857\n",
      "[7]\teval-auc:0.981502\ttrain-auc:0.999909\n",
      "[8]\teval-auc:0.981978\ttrain-auc:0.999918\n",
      "[9]\teval-auc:0.983435\ttrain-auc:0.999933\n",
      "[10]\teval-auc:0.983061\ttrain-auc:0.999937\n",
      "[11]\teval-auc:0.982993\ttrain-auc:0.999933\n",
      "[12]\teval-auc:0.983742\ttrain-auc:0.999943\n",
      "[13]\teval-auc:0.984172\ttrain-auc:0.999954\n",
      "[14]\teval-auc:0.984512\ttrain-auc:0.999956\n",
      "[15]\teval-auc:0.98407\ttrain-auc:0.999958\n",
      "[16]\teval-auc:0.983855\ttrain-auc:0.999959\n",
      "[17]\teval-auc:0.983651\ttrain-auc:0.999964\n",
      "[18]\teval-auc:0.98339\ttrain-auc:0.999962\n",
      "[19]\teval-auc:0.98356\ttrain-auc:0.99997\n",
      "[20]\teval-auc:0.984116\ttrain-auc:0.99997\n",
      "[21]\teval-auc:0.984274\ttrain-auc:0.999967\n",
      "[22]\teval-auc:0.984739\ttrain-auc:0.999963\n",
      "[23]\teval-auc:0.984365\ttrain-auc:0.99997\n",
      "[24]\teval-auc:0.984274\ttrain-auc:0.999972\n",
      "[25]\teval-auc:0.984399\ttrain-auc:0.99997\n",
      "[26]\teval-auc:0.984864\ttrain-auc:0.999964\n",
      "[27]\teval-auc:0.984456\ttrain-auc:0.999973\n",
      "[28]\teval-auc:0.984184\ttrain-auc:0.999977\n",
      "[29]\teval-auc:0.984444\ttrain-auc:0.999973\n",
      "True Positives(spam) = 284\n",
      "True Negatives(ham)  = 283\n",
      "False Positives(actual=ham, predicted=spam) = 17\n",
      "False Negatives(actual=spam,predicted=ham) = 10\n",
      "Accuracy = 95.29%\n",
      "Recall = 96.60%\n",
      "Specificity = 94.33%\n",
      "[0]\teval-auc:0.965099\ttrain-auc:0.998106\n",
      "[1]\teval-auc:0.981854\ttrain-auc:0.999823\n",
      "[2]\teval-auc:0.984429\ttrain-auc:0.999968\n",
      "[3]\teval-auc:0.992028\ttrain-auc:0.999992\n",
      "[4]\teval-auc:0.993625\ttrain-auc:0.999999\n",
      "[5]\teval-auc:0.994622\ttrain-auc:1\n",
      "[6]\teval-auc:0.994396\ttrain-auc:1\n",
      "[7]\teval-auc:0.995217\ttrain-auc:1\n",
      "[8]\teval-auc:0.995064\ttrain-auc:1\n",
      "[9]\teval-auc:0.995696\ttrain-auc:1\n",
      "[10]\teval-auc:0.995472\ttrain-auc:1\n",
      "[11]\teval-auc:0.995713\ttrain-auc:1\n",
      "[12]\teval-auc:0.995773\ttrain-auc:1\n",
      "[13]\teval-auc:0.995919\ttrain-auc:1\n",
      "[14]\teval-auc:0.995928\ttrain-auc:1\n",
      "[15]\teval-auc:0.996349\ttrain-auc:1\n",
      "[16]\teval-auc:0.996181\ttrain-auc:1\n",
      "[17]\teval-auc:0.996095\ttrain-auc:1\n",
      "[18]\teval-auc:0.996138\ttrain-auc:1\n",
      "[19]\teval-auc:0.99616\ttrain-auc:1\n",
      "[20]\teval-auc:0.996164\ttrain-auc:1\n",
      "[21]\teval-auc:0.996173\ttrain-auc:1\n",
      "[22]\teval-auc:0.996156\ttrain-auc:1\n",
      "[23]\teval-auc:0.996151\ttrain-auc:1\n",
      "[24]\teval-auc:0.996052\ttrain-auc:1\n",
      "[25]\teval-auc:0.996074\ttrain-auc:1\n",
      "[26]\teval-auc:0.996031\ttrain-auc:1\n",
      "[27]\teval-auc:0.995958\ttrain-auc:1\n",
      "[28]\teval-auc:0.996065\ttrain-auc:1\n",
      "[29]\teval-auc:0.996065\ttrain-auc:1\n",
      "True Positives(spam) = 767\n",
      "True Negatives(ham)  = 281\n",
      "False Positives(actual=ham, predicted=spam) = 19\n",
      "False Negatives(actual=spam,predicted=ham) = 9\n",
      "Accuracy = 97.31%\n",
      "Recall = 98.84%\n",
      "Specificity = 93.67%\n",
      "[0]\teval-auc:0.973447\ttrain-auc:0.994539\n",
      "[1]\teval-auc:0.987202\ttrain-auc:0.999447\n",
      "[2]\teval-auc:0.992564\ttrain-auc:0.999762\n",
      "[3]\teval-auc:0.99411\ttrain-auc:0.999913\n",
      "[4]\teval-auc:0.995173\ttrain-auc:0.999955\n",
      "[5]\teval-auc:0.994973\ttrain-auc:0.999974\n",
      "[6]\teval-auc:0.995045\ttrain-auc:0.999985\n",
      "[7]\teval-auc:0.994925\ttrain-auc:0.999992\n",
      "[8]\teval-auc:0.994575\ttrain-auc:0.999996\n",
      "[9]\teval-auc:0.99422\ttrain-auc:0.999997\n",
      "[10]\teval-auc:0.994941\ttrain-auc:0.999999\n",
      "[11]\teval-auc:0.99544\ttrain-auc:1\n",
      "[12]\teval-auc:0.995077\ttrain-auc:0.999999\n",
      "[13]\teval-auc:0.994778\ttrain-auc:0.999999\n",
      "[14]\teval-auc:0.994439\ttrain-auc:0.999999\n",
      "[15]\teval-auc:0.994513\ttrain-auc:0.999999\n",
      "[16]\teval-auc:0.994395\ttrain-auc:1\n",
      "[17]\teval-auc:0.994148\ttrain-auc:1\n",
      "[18]\teval-auc:0.994096\ttrain-auc:1\n",
      "[19]\teval-auc:0.994343\ttrain-auc:1\n",
      "[20]\teval-auc:0.994216\ttrain-auc:1\n",
      "[21]\teval-auc:0.994343\ttrain-auc:1\n",
      "[22]\teval-auc:0.994112\ttrain-auc:1\n",
      "[23]\teval-auc:0.99424\ttrain-auc:1\n",
      "[24]\teval-auc:0.994435\ttrain-auc:1\n",
      "[25]\teval-auc:0.994371\ttrain-auc:1\n",
      "[26]\teval-auc:0.994343\ttrain-auc:1\n",
      "[27]\teval-auc:0.994248\ttrain-auc:1\n",
      "[28]\teval-auc:0.994174\ttrain-auc:1\n",
      "[29]\teval-auc:0.99412\ttrain-auc:1\n",
      "True Positives(spam) = 835\n",
      "True Negatives(ham)  = 285\n",
      "False Positives(actual=ham, predicted=spam) = 14\n",
      "False Negatives(actual=spam,predicted=ham) = 4\n",
      "Accuracy = 98.33%\n",
      "Recall = 99.52%\n",
      "Specificity = 95.32%\n"
     ]
    }
   ],
   "source": [
    "# Creating indiviual xgboost models for enron 7 to 12 dataset separately\n",
    "enron_measure_model_df = pd.DataFrame(columns=[\"Enron_dataset\",\"spam\",\"ham\",\"train_spam\",\"train_ham\",\n",
    "                                            \"test_spam\",\"test_ham\",\"tp\",\"tn\",\"fp\",\"fn\",\"acc\",\"recall\",\"specificity\"])\n",
    "\n",
    "enron_dataset_list_df = [enron7,enron8,enron9,enron10,enron11,enron12]\n",
    "j=0\n",
    "for ernron_df in enron_dataset_list_df:\n",
    "    \n",
    "    col_attributes=[]\n",
    "    with open(\"Res/processed_data/attributes_names.txt\", 'r') as f:\n",
    "            col_attributes.extend(f.read().split())\n",
    "    # Baseline Features for the logistic regression model\n",
    "    baseline_X_features = ['line_count', 'token_count', 'punctuations_count', 'single_char_count', \n",
    "                         'number_token_count', 'year_count', 'stopword_count','median_useful_token_len', \n",
    "                         'avg_useful_token_len', 'rareword_count','attributes_len']\n",
    "    baseline_X_features.extend(col_attributes)\n",
    "    Y_feature = \"mail_label\"\n",
    "\n",
    "    # Subsetting the data as X and y\n",
    "    spam = ernron_df[ernron_df[\"mail_label\"]==\"spam\"]\n",
    "    ham = ernron_df[ernron_df[\"mail_label\"]==\"ham\"]\n",
    "\n",
    "    X_train_spam, X_test_spam, y_train_spam, y_test_spam = \\\n",
    "    train_test_split(spam[baseline_X_features], spam[Y_feature], test_size=0.2, random_state=0)\n",
    "\n",
    "    X_train_ham, X_test_ham, y_train_ham, y_test_ham = \\\n",
    "    train_test_split(ham[baseline_X_features], ham[Y_feature], test_size=0.2, random_state=0)\n",
    "\n",
    "    X_train = pd.concat([X_train_spam,X_train_ham])\n",
    "    X_test = pd.concat([X_test_spam,X_test_ham])\n",
    "    y_train = pd.concat([y_train_spam,y_train_ham])\n",
    "    y_test = pd.concat([y_test_spam,y_test_ham])\n",
    "    y_train[\"label\"] = y_train.apply(lambda x: 1.0 if x==\"spam\" else 0.0)\n",
    "    y_test[\"label\"] = y_test.apply(lambda x: 1.0 if x==\"spam\" else 0.0)\n",
    "\n",
    "    dtrain = xgb.DMatrix(X_train, label=y_train[\"label\"])\n",
    "    dtest = xgb.DMatrix(X_test, label=y_test[\"label\"])\n",
    "\n",
    "    param = {'max_depth': 100, 'eta': 1, 'verbosity': 0, 'objective': 'binary:logistic',\"n_estimators\": [200]}\n",
    "    param['nthread'] = 4\n",
    "    param['eval_metric'] =  ['auc']\n",
    "\n",
    "    evallist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "\n",
    "    num_round = 30\n",
    "    clf = xgb.train(param, dtrain, num_round, evallist)\n",
    "\n",
    "    y_pred = clf.predict(dtest)\n",
    "    y_probas = y_pred # predicted probabilities generated by sklearn classifier\n",
    "    y_pred = pd.Series(y_pred).apply(lambda x: 1.0 if x>0.5 else 0.0)\n",
    "\n",
    "    tn, fp, fn, tp = confusion_matrix(y_test[\"label\"], y_pred).ravel()\n",
    "    print(\"True Positives(spam) = {}\".format(tp))\n",
    "    print(\"True Negatives(ham)  = {}\".format(tn))\n",
    "    print(\"False Positives(actual=ham, predicted=spam) = {}\".format(fp))\n",
    "    print(\"False Negatives(actual=spam,predicted=ham) = {}\".format(fn))\n",
    "    print(\"Accuracy = {:.2f}%\".format((tp+tn)/float(len(y_test))*100))\n",
    "    print(\"Recall = {:.2f}%\".format((tp/float(tp+fn))*100))\n",
    "    print(\"Specificity = {:.2f}%\".format((tn/float(tn+fp))*100))\n",
    "    \n",
    "    enron_measure_model_df.loc[j]= [\"Enron\"+str(j+7),\n",
    "           len(spam),len(ham),len(X_train_spam),len(X_train_ham),\n",
    "           len(X_test_spam),len(X_test_ham),\n",
    "           tp,tn,fp,fn,\n",
    "           (tp+tn)/float(len(y_test))*100,\n",
    "           (tp/float(tp+fn))*100,\n",
    "           (tn/float(tn+fp))*100]\n",
    "    j+=1\n",
    "enron_measure_model_df.to_csv(\"Res/Complete_data_processed/enron_measure_model.csv\",sep=\",\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enron_dataset</th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "      <th>train_spam</th>\n",
       "      <th>train_ham</th>\n",
       "      <th>test_spam</th>\n",
       "      <th>test_ham</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1064</td>\n",
       "      <td>2929</td>\n",
       "      <td>266</td>\n",
       "      <td>733</td>\n",
       "      <td>250</td>\n",
       "      <td>712</td>\n",
       "      <td>21</td>\n",
       "      <td>16</td>\n",
       "      <td>96.200000</td>\n",
       "      <td>93.984962</td>\n",
       "      <td>97.135061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1032</td>\n",
       "      <td>3484</td>\n",
       "      <td>258</td>\n",
       "      <td>872</td>\n",
       "      <td>250</td>\n",
       "      <td>866</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>98.673740</td>\n",
       "      <td>96.899225</td>\n",
       "      <td>99.311927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1109</td>\n",
       "      <td>1877</td>\n",
       "      <td>278</td>\n",
       "      <td>470</td>\n",
       "      <td>259</td>\n",
       "      <td>456</td>\n",
       "      <td>14</td>\n",
       "      <td>19</td>\n",
       "      <td>95.460614</td>\n",
       "      <td>93.165468</td>\n",
       "      <td>97.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1172</td>\n",
       "      <td>1198</td>\n",
       "      <td>294</td>\n",
       "      <td>300</td>\n",
       "      <td>284</td>\n",
       "      <td>283</td>\n",
       "      <td>17</td>\n",
       "      <td>10</td>\n",
       "      <td>95.294118</td>\n",
       "      <td>96.598639</td>\n",
       "      <td>94.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3102</td>\n",
       "      <td>1199</td>\n",
       "      <td>776</td>\n",
       "      <td>300</td>\n",
       "      <td>767</td>\n",
       "      <td>281</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>97.307335</td>\n",
       "      <td>98.840206</td>\n",
       "      <td>93.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>3353</td>\n",
       "      <td>1194</td>\n",
       "      <td>839</td>\n",
       "      <td>299</td>\n",
       "      <td>835</td>\n",
       "      <td>285</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "      <td>98.331870</td>\n",
       "      <td>99.523242</td>\n",
       "      <td>95.317726</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Enron_dataset  spam   ham train_spam train_ham test_spam test_ham   tp   tn  \\\n",
       "0        Enron7  1330  3662       1064      2929       266      733  250  712   \n",
       "1        Enron8  1290  4356       1032      3484       258      872  250  866   \n",
       "2        Enron9  1387  2347       1109      1877       278      470  259  456   \n",
       "3       Enron10  1466  1498       1172      1198       294      300  284  283   \n",
       "4       Enron11  3878  1499       3102      1199       776      300  767  281   \n",
       "5       Enron12  4192  1493       3353      1194       839      299  835  285   \n",
       "\n",
       "   fp  fn        acc     recall  specificity  \n",
       "0  21  16  96.200000  93.984962    97.135061  \n",
       "1   6   8  98.673740  96.899225    99.311927  \n",
       "2  14  19  95.460614  93.165468    97.021277  \n",
       "3  17  10  95.294118  96.598639    94.333333  \n",
       "4  19   9  97.307335  98.840206    93.666667  \n",
       "5  14   4  98.331870  99.523242    95.317726  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enron_measure_model_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Enron_dataset</th>\n",
       "      <th>model_name</th>\n",
       "      <th>spam</th>\n",
       "      <th>ham</th>\n",
       "      <th>tp</th>\n",
       "      <th>tn</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>acc</th>\n",
       "      <th>recall</th>\n",
       "      <th>specificity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1229</td>\n",
       "      <td>3316</td>\n",
       "      <td>346</td>\n",
       "      <td>101</td>\n",
       "      <td>91.045673</td>\n",
       "      <td>92.406015</td>\n",
       "      <td>90.551611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1068</td>\n",
       "      <td>2994</td>\n",
       "      <td>668</td>\n",
       "      <td>262</td>\n",
       "      <td>81.370192</td>\n",
       "      <td>80.300752</td>\n",
       "      <td>81.758602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>877</td>\n",
       "      <td>2604</td>\n",
       "      <td>1058</td>\n",
       "      <td>453</td>\n",
       "      <td>69.731571</td>\n",
       "      <td>65.939850</td>\n",
       "      <td>71.108684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1324</td>\n",
       "      <td>1575</td>\n",
       "      <td>2087</td>\n",
       "      <td>6</td>\n",
       "      <td>58.072917</td>\n",
       "      <td>99.548872</td>\n",
       "      <td>43.009285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1226</td>\n",
       "      <td>2436</td>\n",
       "      <td>1226</td>\n",
       "      <td>104</td>\n",
       "      <td>73.357372</td>\n",
       "      <td>92.180451</td>\n",
       "      <td>66.521027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Enron7</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>1330</td>\n",
       "      <td>3662</td>\n",
       "      <td>1140</td>\n",
       "      <td>2583</td>\n",
       "      <td>1079</td>\n",
       "      <td>190</td>\n",
       "      <td>74.579327</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>70.535227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1250</td>\n",
       "      <td>3198</td>\n",
       "      <td>1158</td>\n",
       "      <td>40</td>\n",
       "      <td>78.781438</td>\n",
       "      <td>96.899225</td>\n",
       "      <td>73.415978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1161</td>\n",
       "      <td>4193</td>\n",
       "      <td>163</td>\n",
       "      <td>129</td>\n",
       "      <td>94.828197</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>96.258035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1238</td>\n",
       "      <td>3372</td>\n",
       "      <td>984</td>\n",
       "      <td>52</td>\n",
       "      <td>81.650726</td>\n",
       "      <td>95.968992</td>\n",
       "      <td>77.410468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1288</td>\n",
       "      <td>2260</td>\n",
       "      <td>2096</td>\n",
       "      <td>2</td>\n",
       "      <td>62.840949</td>\n",
       "      <td>99.844961</td>\n",
       "      <td>51.882461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1275</td>\n",
       "      <td>3024</td>\n",
       "      <td>1332</td>\n",
       "      <td>15</td>\n",
       "      <td>76.142402</td>\n",
       "      <td>98.837209</td>\n",
       "      <td>69.421488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Enron8</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>1290</td>\n",
       "      <td>4356</td>\n",
       "      <td>1251</td>\n",
       "      <td>2868</td>\n",
       "      <td>1488</td>\n",
       "      <td>39</td>\n",
       "      <td>72.954304</td>\n",
       "      <td>96.976744</td>\n",
       "      <td>65.840220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1302</td>\n",
       "      <td>1735</td>\n",
       "      <td>612</td>\n",
       "      <td>85</td>\n",
       "      <td>81.333690</td>\n",
       "      <td>93.871665</td>\n",
       "      <td>73.924159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1237</td>\n",
       "      <td>1847</td>\n",
       "      <td>500</td>\n",
       "      <td>150</td>\n",
       "      <td>82.592394</td>\n",
       "      <td>89.185292</td>\n",
       "      <td>78.696208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1143</td>\n",
       "      <td>1894</td>\n",
       "      <td>453</td>\n",
       "      <td>244</td>\n",
       "      <td>81.333690</td>\n",
       "      <td>82.408075</td>\n",
       "      <td>80.698764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1383</td>\n",
       "      <td>1127</td>\n",
       "      <td>1220</td>\n",
       "      <td>4</td>\n",
       "      <td>67.220139</td>\n",
       "      <td>99.711608</td>\n",
       "      <td>48.018747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1348</td>\n",
       "      <td>1392</td>\n",
       "      <td>955</td>\n",
       "      <td>39</td>\n",
       "      <td>73.379754</td>\n",
       "      <td>97.188176</td>\n",
       "      <td>59.309757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Enron9</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>1387</td>\n",
       "      <td>2347</td>\n",
       "      <td>1292</td>\n",
       "      <td>1946</td>\n",
       "      <td>401</td>\n",
       "      <td>95</td>\n",
       "      <td>86.716658</td>\n",
       "      <td>93.150685</td>\n",
       "      <td>82.914359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1355</td>\n",
       "      <td>605</td>\n",
       "      <td>893</td>\n",
       "      <td>111</td>\n",
       "      <td>66.126856</td>\n",
       "      <td>92.428377</td>\n",
       "      <td>40.387183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1185</td>\n",
       "      <td>553</td>\n",
       "      <td>945</td>\n",
       "      <td>281</td>\n",
       "      <td>58.636977</td>\n",
       "      <td>80.832196</td>\n",
       "      <td>36.915888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>969</td>\n",
       "      <td>640</td>\n",
       "      <td>858</td>\n",
       "      <td>497</td>\n",
       "      <td>54.284750</td>\n",
       "      <td>66.098226</td>\n",
       "      <td>42.723632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1460</td>\n",
       "      <td>1333</td>\n",
       "      <td>165</td>\n",
       "      <td>6</td>\n",
       "      <td>94.230769</td>\n",
       "      <td>99.590723</td>\n",
       "      <td>88.985314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1348</td>\n",
       "      <td>407</td>\n",
       "      <td>1091</td>\n",
       "      <td>118</td>\n",
       "      <td>59.210526</td>\n",
       "      <td>91.950887</td>\n",
       "      <td>27.169559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Enron10</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>1466</td>\n",
       "      <td>1498</td>\n",
       "      <td>1255</td>\n",
       "      <td>412</td>\n",
       "      <td>1086</td>\n",
       "      <td>211</td>\n",
       "      <td>56.241565</td>\n",
       "      <td>85.607094</td>\n",
       "      <td>27.503338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3767</td>\n",
       "      <td>1178</td>\n",
       "      <td>321</td>\n",
       "      <td>111</td>\n",
       "      <td>91.965780</td>\n",
       "      <td>97.137700</td>\n",
       "      <td>78.585724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3418</td>\n",
       "      <td>1315</td>\n",
       "      <td>184</td>\n",
       "      <td>460</td>\n",
       "      <td>88.023061</td>\n",
       "      <td>88.138216</td>\n",
       "      <td>87.725150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3676</td>\n",
       "      <td>1269</td>\n",
       "      <td>230</td>\n",
       "      <td>202</td>\n",
       "      <td>91.965780</td>\n",
       "      <td>94.791129</td>\n",
       "      <td>84.656438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3870</td>\n",
       "      <td>767</td>\n",
       "      <td>732</td>\n",
       "      <td>8</td>\n",
       "      <td>86.237679</td>\n",
       "      <td>99.793708</td>\n",
       "      <td>51.167445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3824</td>\n",
       "      <td>1351</td>\n",
       "      <td>148</td>\n",
       "      <td>54</td>\n",
       "      <td>96.243258</td>\n",
       "      <td>98.607530</td>\n",
       "      <td>90.126751</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Enron11</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>3878</td>\n",
       "      <td>1499</td>\n",
       "      <td>3748</td>\n",
       "      <td>1074</td>\n",
       "      <td>425</td>\n",
       "      <td>130</td>\n",
       "      <td>89.678259</td>\n",
       "      <td>96.647757</td>\n",
       "      <td>71.647765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron1_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>3927</td>\n",
       "      <td>1103</td>\n",
       "      <td>390</td>\n",
       "      <td>265</td>\n",
       "      <td>88.478452</td>\n",
       "      <td>93.678435</td>\n",
       "      <td>73.878098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron2_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>3700</td>\n",
       "      <td>1141</td>\n",
       "      <td>352</td>\n",
       "      <td>492</td>\n",
       "      <td>85.153914</td>\n",
       "      <td>88.263359</td>\n",
       "      <td>76.423309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron3_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>3497</td>\n",
       "      <td>1409</td>\n",
       "      <td>84</td>\n",
       "      <td>695</td>\n",
       "      <td>86.297274</td>\n",
       "      <td>83.420802</td>\n",
       "      <td>94.373744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron4_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>4175</td>\n",
       "      <td>790</td>\n",
       "      <td>703</td>\n",
       "      <td>17</td>\n",
       "      <td>87.335092</td>\n",
       "      <td>99.594466</td>\n",
       "      <td>52.913597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron5_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>4063</td>\n",
       "      <td>936</td>\n",
       "      <td>557</td>\n",
       "      <td>129</td>\n",
       "      <td>87.933157</td>\n",
       "      <td>96.922710</td>\n",
       "      <td>62.692565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Enron12</td>\n",
       "      <td>enron6_xgboost</td>\n",
       "      <td>4192</td>\n",
       "      <td>1493</td>\n",
       "      <td>3940</td>\n",
       "      <td>1036</td>\n",
       "      <td>457</td>\n",
       "      <td>252</td>\n",
       "      <td>87.528584</td>\n",
       "      <td>93.988550</td>\n",
       "      <td>69.390489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Enron_dataset      model_name  spam   ham    tp    tn    fp   fn  \\\n",
       "0         Enron7  enron1_xgboost  1330  3662  1229  3316   346  101   \n",
       "1         Enron7  enron2_xgboost  1330  3662  1068  2994   668  262   \n",
       "2         Enron7  enron3_xgboost  1330  3662   877  2604  1058  453   \n",
       "3         Enron7  enron4_xgboost  1330  3662  1324  1575  2087    6   \n",
       "4         Enron7  enron5_xgboost  1330  3662  1226  2436  1226  104   \n",
       "5         Enron7  enron6_xgboost  1330  3662  1140  2583  1079  190   \n",
       "6         Enron8  enron1_xgboost  1290  4356  1250  3198  1158   40   \n",
       "7         Enron8  enron2_xgboost  1290  4356  1161  4193   163  129   \n",
       "8         Enron8  enron3_xgboost  1290  4356  1238  3372   984   52   \n",
       "9         Enron8  enron4_xgboost  1290  4356  1288  2260  2096    2   \n",
       "10        Enron8  enron5_xgboost  1290  4356  1275  3024  1332   15   \n",
       "11        Enron8  enron6_xgboost  1290  4356  1251  2868  1488   39   \n",
       "12        Enron9  enron1_xgboost  1387  2347  1302  1735   612   85   \n",
       "13        Enron9  enron2_xgboost  1387  2347  1237  1847   500  150   \n",
       "14        Enron9  enron3_xgboost  1387  2347  1143  1894   453  244   \n",
       "15        Enron9  enron4_xgboost  1387  2347  1383  1127  1220    4   \n",
       "16        Enron9  enron5_xgboost  1387  2347  1348  1392   955   39   \n",
       "17        Enron9  enron6_xgboost  1387  2347  1292  1946   401   95   \n",
       "18       Enron10  enron1_xgboost  1466  1498  1355   605   893  111   \n",
       "19       Enron10  enron2_xgboost  1466  1498  1185   553   945  281   \n",
       "20       Enron10  enron3_xgboost  1466  1498   969   640   858  497   \n",
       "21       Enron10  enron4_xgboost  1466  1498  1460  1333   165    6   \n",
       "22       Enron10  enron5_xgboost  1466  1498  1348   407  1091  118   \n",
       "23       Enron10  enron6_xgboost  1466  1498  1255   412  1086  211   \n",
       "24       Enron11  enron1_xgboost  3878  1499  3767  1178   321  111   \n",
       "25       Enron11  enron2_xgboost  3878  1499  3418  1315   184  460   \n",
       "26       Enron11  enron3_xgboost  3878  1499  3676  1269   230  202   \n",
       "27       Enron11  enron4_xgboost  3878  1499  3870   767   732    8   \n",
       "28       Enron11  enron5_xgboost  3878  1499  3824  1351   148   54   \n",
       "29       Enron11  enron6_xgboost  3878  1499  3748  1074   425  130   \n",
       "30       Enron12  enron1_xgboost  4192  1493  3927  1103   390  265   \n",
       "31       Enron12  enron2_xgboost  4192  1493  3700  1141   352  492   \n",
       "32       Enron12  enron3_xgboost  4192  1493  3497  1409    84  695   \n",
       "33       Enron12  enron4_xgboost  4192  1493  4175   790   703   17   \n",
       "34       Enron12  enron5_xgboost  4192  1493  4063   936   557  129   \n",
       "35       Enron12  enron6_xgboost  4192  1493  3940  1036   457  252   \n",
       "\n",
       "          acc     recall  specificity  \n",
       "0   91.045673  92.406015    90.551611  \n",
       "1   81.370192  80.300752    81.758602  \n",
       "2   69.731571  65.939850    71.108684  \n",
       "3   58.072917  99.548872    43.009285  \n",
       "4   73.357372  92.180451    66.521027  \n",
       "5   74.579327  85.714286    70.535227  \n",
       "6   78.781438  96.899225    73.415978  \n",
       "7   94.828197  90.000000    96.258035  \n",
       "8   81.650726  95.968992    77.410468  \n",
       "9   62.840949  99.844961    51.882461  \n",
       "10  76.142402  98.837209    69.421488  \n",
       "11  72.954304  96.976744    65.840220  \n",
       "12  81.333690  93.871665    73.924159  \n",
       "13  82.592394  89.185292    78.696208  \n",
       "14  81.333690  82.408075    80.698764  \n",
       "15  67.220139  99.711608    48.018747  \n",
       "16  73.379754  97.188176    59.309757  \n",
       "17  86.716658  93.150685    82.914359  \n",
       "18  66.126856  92.428377    40.387183  \n",
       "19  58.636977  80.832196    36.915888  \n",
       "20  54.284750  66.098226    42.723632  \n",
       "21  94.230769  99.590723    88.985314  \n",
       "22  59.210526  91.950887    27.169559  \n",
       "23  56.241565  85.607094    27.503338  \n",
       "24  91.965780  97.137700    78.585724  \n",
       "25  88.023061  88.138216    87.725150  \n",
       "26  91.965780  94.791129    84.656438  \n",
       "27  86.237679  99.793708    51.167445  \n",
       "28  96.243258  98.607530    90.126751  \n",
       "29  89.678259  96.647757    71.647765  \n",
       "30  88.478452  93.678435    73.878098  \n",
       "31  85.153914  88.263359    76.423309  \n",
       "32  86.297274  83.420802    94.373744  \n",
       "33  87.335092  99.594466    52.913597  \n",
       "34  87.933157  96.922710    62.692565  \n",
       "35  87.528584  93.988550    69.390489  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_enron_accuracy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed!\n"
     ]
    }
   ],
   "source": [
    "print(\"Completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
